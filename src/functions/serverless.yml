service: aws-building-permits-pipeline

plugins:
  - serverless-python-requirements

package:
  individually: true

custom:
  pythonRequirements:
    dockerizePip: non-linux
  bucket: aws-permits-analysis
  s3_raw_folder: "data/raw/"
  s3_int_folder: "data/interim/"
  s3_processed_folder: "data/processed/"
  #permits_url: "https://data.lacity.org/api/views/yv23-pmwf/rows.csv"
  permits_url: "https://query.data.world/s/3jh2lg45et7dhrpolk4in4ye24mnaj"
  filename: "titanic"
  db_name: ${ssm:/permits/db_name}
  db_user: ${ssm:/permits/db_user}
  db_password: ${ssm:/permits/db_password~true}
  db_port: ${cf:aws-building-permits-pipeline-cfn-3.PortDB}
  db_endpoint: ${cf:aws-building-permits-pipeline-cfn-3.EndpointDB} # remember to add "-cfn" to stack name
  
provider:
  name: aws
  runtime: python3.7
  stage: dev
  region: us-east-1
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:PutObject
        - s3:PutObjectAcl
        - s3:PutBucketNotification
        - s3:GetObject
        - s3:ListBucket
        - s3:GetObjectAcl
      Resource: arn:aws:s3:::${self:custom.bucket}/*
functions:
  initDatabase:
    handler: init_db.init_db
    package:
      include:
          - libs/sql_queries.py
    layers: 
      - arn:aws:lambda:us-east-1:898466741470:layer:psycopg2-py37:3
    timeout: 30
    memorySize: 128
    environment:
      DB_NAME: ${self:custom.db_name}
      DB_USER: ${self:custom.db_user}
      DB_PASSWORD: ${self:custom.db_password}
      DB_PORT: ${self:custom.db_port}
      DB_ENDPOINT: ${self:custom.db_endpoint}
  fetchData:
    handler: fetch_data.fetch_data
    layers: 
      - arn:aws:lambda:us-east-1:531868584498:layer:requestsLayer-p36-p37-p38:1
    timeout: 200
    memorySize: 1536
    environment:
      S3_BUCKET: ${self:custom.bucket}
      S3_RAW_FOLDER: ${self:custom.s3_raw_folder}
      S3_INT_FOLDER: ${self:custom.s3_int_folder}
      S3_PROCESSED_FOLDER: ${self:custom.s3_processed_folder}
      PERMITS_URL: ${self:custom.permits_url}
      FILENAME: ${self:custom.filename}
    events:
      - schedule: rate(24 hours)
  loadData:
    handler: load_data.load_data
    package:
      include:
          - libs/sql_queries.py
    layers:
      - arn:aws:lambda:us-east-1:898466741470:layer:psycopg2-py37:3
    timeout: 120
    memorySize: 128
    environment:
      DB_NAME: ${self:custom.db_name}
      DB_USER: ${self:custom.db_user}
      DB_PASSWORD: ${self:custom.db_password}
      DB_PORT: ${self:custom.db_port}
      DB_ENDPOINT: ${self:custom.db_endpoint}
    events:
      - s3:
          bucket: ${self:custom.bucket}
          event: s3:ObjectCreated:*
          rules:
            - prefix: ${self:custom.s3_raw_folder}
            - suffix: .csv
          existing: true